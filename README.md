# CPU Scheduler Simulation Project
### ğŸ“‹ Project Overview
A comprehensive discrete-event simulation framework for evaluating and comparing CPU scheduling algorithms under various workload conditions.

### ğŸ¯ Objectives
- Design and implement a simulation framework for CPU scheduling algorithms
- Evaluate and compare algorithm performance using standard metrics
- Analyze sensitivity to different parameters and workload characteristics
- Provide comprehensive visualization of results

### ğŸ“š Learning Outcomes
- Understand internal workings of CPU scheduling algorithms
- Develop skills in discrete-event simulation
- Analyze and interpret performance metrics
- Compare algorithm effectiveness under different scenarios
- Practice scientific methodology in computer systems evaluation

## ğŸ—ï¸ Project Structure

cpu-scheduler-simulation/
â”œâ”€â”€ src/ # Source code
â”‚ â”œâ”€â”€ main.py # Main entry point
â”‚ â”œâ”€â”€ simulator.py # Discrete-event simulation engine
â”‚ â”œâ”€â”€ schedulers/ # Scheduling algorithms
â”‚ â”œâ”€â”€ process_generator.py # Workload generation
â”‚ â”œâ”€â”€ statistics.py # Performance metrics calculation
â”‚ â”œâ”€â”€ visualization.py # Visualization generation
â”‚ â””â”€â”€ experiments.py # Experimental design
â”œâ”€â”€ data/ # Data files
â”‚ â”œâ”€â”€ trace_files/ # Sample trace files
â”‚ â””â”€â”€ results/ # Output results
â”œâ”€â”€ docs/ # Documentation
â”œâ”€â”€ tests/ # Unit tests
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ config.yaml # Configuration
â”œâ”€â”€ run_experiments.py # Experiment runner
â””â”€â”€ README.md # This file


## ğŸš€ Getting Started

### Prerequisites
- Python 3.8 or higher
- pip package manager

### Installation

1. Clone the repository:
```bash
git clone https://github.com/yourusername/cpu-scheduler-simulation.git
cd cpu-scheduler-simulation
```

2. Install dependencies
```bash 
pip install -r requirements.txt
```
3. Create sample data:
``` bash 
python -c "from src.process_generator import ProcessGenerator; pg = ProcessGenerator(); pg.create_sample_trace_files()"
```
Basic Usage
1. Run a single simulation:
```bash
python src/main.py --algorithm fcfs --processes 500 --visualize
```
2. run all expriment:
```bash
python run_experiments.py
```
3. Run specific experiment: 
```bash
python run_experiments.py --experiment baseline --visualize
```

## ğŸ“Š Implemented Scheduling Algorithms

    First-Come, First-Served (FCFS) - Non-preemptive

    Shortest Job First (SJF) - Both preemptive (SRTF) and non-preemptive versions

    Round Robin (RR) - Configurable time quantum

    Priority Scheduling - Both preemptive and non-preemptive with aging

    Multilevel Feedback Queue (MLFQ) - Bonus feature

## ğŸ”¬ Experimental Design
### 1. Baseline Comparison

    Compare all algorithms with identical workload (500 processes, mixed characteristics)

    Collect and compare all performance metrics

### 2. Sensitivity Analysis

    Vary time quantum for RR (5, 10, 20, 50, 100ms)

    Vary number of processes (100, 500, 1000)

### 3. Workload-Specific Performance

    Test with CPU-intensive workload

    Test with I/O-intensive workload

    Test with mixed workload

### 4. Scalability Test

    Measure performance with increasing system load

    Plot metrics vs. number of processes

## ğŸ“ˆ Performance Metrics
### Per-Process Metrics

    Turnaround Time: Tturnaround=Tcompletionâˆ’TarrivalTturnaroundâ€‹=Tcompletionâ€‹âˆ’Tarrivalâ€‹

    Waiting Time: Twaiting=Tturnaroundâˆ’TburstTwaitingâ€‹=Tturnaroundâ€‹âˆ’Tburstâ€‹

    Response Time: Tresponse=Tfirst_runâˆ’TarrivalTresponseâ€‹=Tfirst_runâ€‹âˆ’Tarrivalâ€‹

### System-Wide Metrics

    Average Turnaround Time

    Average Waiting Time

    Average Response Time

    CPU Utilization: UCPU=âˆ‘CPU_burst_timeTotal_simulation_timeÃ—100%UCPUâ€‹=Total_simulation_timeâˆ‘CPU_burst_timeâ€‹Ã—100%

    Throughput: Number of processes completed per unit time

    Fairness Index (Jain's Fairness): F=(âˆ‘i=1nxi)2nÃ—âˆ‘i=1nxi2F=nÃ—âˆ‘i=1nâ€‹xi2â€‹(âˆ‘i=1nâ€‹xiâ€‹)2â€‹


## ğŸ“Š Visualization Outputs
per unit time

    Fairness Index (Jain's Fairness): F=(âˆ‘i=1nxi)2nÃ—âˆ‘i=1nxi2F=nÃ—âˆ‘i=1nâ€‹xi2â€‹(âˆ‘i=1nâ€‹xiâ€‹)2â€‹


## ğŸ“Š Visualization Outputs

The system generates the following visualizations:

    Gantt charts for each algorithm (first 20 processes)

    Bar charts comparing average metrics across algorithms

    Line graphs showing metric trends with varying parameters

    Box plots showing distribution of waiting times